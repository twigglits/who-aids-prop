# this python script contains core function in RSimpactHelper that have been translated to Python.

import numpy as np
import pandas as pd
from scipy.stats import weibull_min, binomtest, poisson
import os
import shutil
from scipy.stats import poisson
import random

class UniqueSeedGenerator:
    def __init__(self, start=0, end=1000000000):
        self.start = start
        self.end = end
        self.generated_seeds = set()
        
    def generate_seed(self):
        while True:
            seed = random.randint(self.start, self.end)
            if seed not in self.generated_seeds:
                self.generated_seeds.add(seed)
                return seed
            if len(self.generated_seeds) >= (self.end - self.start + 1):
                raise ValueError("All possible seeds have been generated.")
            
def readthedata(modeloutput):
    """
    Read the Simpact output files.

    readthedata imports the .csv files generated by simpact.run in the RSimpactCyan package,
    and combines them into one dictionary object. This object is in a format that makes
    subsequent analysis easier.

    Parameters:
    modeloutput (dict): The dictionary object produced by simpact.run.

    Returns:
    dict: A dictionary containing DataFrames for the output of the model run:
          - ptable: People in the simulation
          - rtable: Relationship information
          - etable: Events
          - ttable: HIV treatment episodes
          - itable: Input parameters
          - ltable: Optional book-keeping log
          - vltable: HIV viral load information
          - ftable: Optional Facility log

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    datalist = readthedata(modeloutput)

    """
    # Extracting paths to the CSV files generated by simpact.run()
    path = str(modeloutput["outputfile"])
    outputID = str(modeloutput["id"])
    DestDir = path.replace(outputID + "output.txt", "")
    personfile = DestDir + outputID + "personlog.csv"
    relationfile = DestDir + outputID + "relationlog.csv"
    eventfile = DestDir + outputID + "eventlog.csv"
    treatmentfile = DestDir + outputID + "treatmentlog.csv"
    inputparamfile = DestDir + outputID + "settingslog.csv"
    periodicfile = DestDir + outputID + "periodiclog.csv"
    viralloadfile = DestDir + outputID + "hivviralloadlog.csv"
    # facilitiesxyfile = DestDir + outputID + "facilitypositions.csv"

    # Reading the CSV files into DataFrames
    ptable = pd.read_csv(personfile, low_memory=False)
    vltable = pd.read_csv(viralloadfile)
    rtable = pd.read_csv(relationfile)
    etable = pd.read_csv(eventfile, low_memory=False, header=None, names=list(range(14)))
    ttable = pd.read_csv(treatmentfile)
    itable = pd.read_csv(inputparamfile)

    # Naming columns in the event log DataFrame
    if etable.shape[1] == 10:
        etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                          "p1age", "p2name", "p2ID", "p2gender", "p2age"]
    elif etable.shape[1] == 12:
        etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                          "p1age", "p2name", "p2ID", "p2gender", "p2age",
                          "extradescript", "value"]
    else:
        etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                          "p1age", "p2name", "p2ID", "p2gender", "p2age",
                          "extradescript", "value","relationage","value1"]

    # Checking for existence of optional logs
    if os.path.exists(periodicfile): #or os.path.exists(facilitiesxyfile):
        ltable = pd.read_csv(periodicfile)
        # ftable = pd.read_csv(facilitiesxyfile)
        outputtables = {
            'ptable': ptable,
            'rtable': rtable,
            'etable': etable,
            'ttable': ttable,
            'itable': itable,
            'ltable': ltable,
            'vltable': vltable
            # 'ftable': ftable
        }
    else:
        outputtables = {
            'ptable': ptable,
            'rtable': rtable,
            'etable': etable,
            'ttable': ttable,
            'itable': itable,
            'vltable': vltable
        }

    return outputtables

def readthedata_from_folder(folder_path):
    """
    Read the Simpact output files from a specified folder.

    readthedata_from_folder imports the .csv files generated by simpact.run in the RSimpactCyan package,
    and combines them into one dictionary object. This object is in a format that makes
    subsequent analysis easier.

    Parameters:
    folder_path (str): The path to the folder containing the .csv files generated by simpact.run.

    Returns:
    dict: A dictionary containing DataFrames for the output of the model run:
          - ptable: People in the simulation
          - rtable: Relationship information
          - etable: Events
          - ttable: HIV treatment episodes
          - itable: Input parameters
          - ltable: Optional book-keeping log
          - vltable: HIV viral load information
          - ftable: Optional Facility log

    Examples:
    folder_path = "path/to/folder"
    datalist = readthedata_from_folder(folder_path)

    """
    # Construct file paths
    folder_name = os.path.basename(folder_path)
    personfile = os.path.join(folder_path, f'{folder_name}personlog.csv')
    relationfile = os.path.join(folder_path, f'{folder_name}relationlog.csv')
    eventfile = os.path.join(folder_path, f'{folder_name}eventlog.csv')
    treatmentfile = os.path.join(folder_path, f'{folder_name}treatmentlog.csv')
    inputparamfile = os.path.join(folder_path, f'{folder_name}settingslog.csv')
    periodicfile = os.path.join(folder_path, f'{folder_name}periodiclog.csv')
    viralloadfile = os.path.join(folder_path, f'{folder_name}hivviralloadlog.csv')
    # facilitiesxyfile = os.path.join(folder_path, f'{folder_name}facilitypositions.csv')

    # Reading the CSV files into DataFrames
    ptable = pd.read_csv(personfile, low_memory=False)
    vltable = pd.read_csv(viralloadfile)
    rtable = pd.read_csv(relationfile)
    etable = pd.read_csv(eventfile, low_memory=False, header=None, names=list(range(14)))
    ttable = pd.read_csv(treatmentfile)
    itable = pd.read_csv(inputparamfile)

    # Naming columns in the event log DataFrame
    if etable.shape[1] == 10:
        etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                          "p1age", "p2name", "p2ID", "p2gender", "p2age"]
    elif etable.shape[1] == 12:
        etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                          "p1age", "p2name", "p2ID", "p2gender", "p2age",
                          "extradescript", "value"]
    else:
        etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                          "p1age", "p2name", "p2ID", "p2gender", "p2age",
                          "extradescript", "value", "relationage", "value1"]

    # Checking for existence of optional logs
    if os.path.exists(periodicfile):  # or os.path.exists(facilitiesxyfile):
        ltable = pd.read_csv(periodicfile)
        # ftable = pd.read_csv(facilitiesxyfile)
        outputtables = {
            'ptable': ptable,
            'rtable': rtable,
            'etable': etable,
            'ttable': ttable,
            'itable': itable,
            'ltable': ltable,
            'vltable': vltable
            # 'ftable': ftable
        }
    else:
        outputtables = {
            'ptable': ptable,
            'rtable': rtable,
            'etable': etable,
            'ttable': ttable,
            'itable': itable,
            'vltable': vltable
        }

    return outputtables

def readthedata_from_multiple_folders(main_folder_path):
    """
    Read the Simpact output files from multiple subfolders.

    readthedata_from_multiple_folders imports the .csv files generated by simpact.run in the RSimpactCyan package,
    from each subfolder within the main folder and combines them into a dictionary of dictionaries. Each sub-dictionary
    corresponds to a subfolder and contains DataFrames for the output of the model run.

    Parameters:
    main_folder_path (str): The path to the main folder containing subfolders with the .csv files generated by simpact.run.

    Returns:
    dict: A dictionary of dictionaries containing DataFrames for the output of the model run for each subfolder:
          Each sub-dictionary contains:
          - ptable: People in the simulation
          - rtable: Relationship information
          - etable: Events
          - ttable: HIV treatment episodes
          - itable: Input parameters
          - ltable: Optional book-keeping log
          - vltable: HIV viral load information
          - ftable: Optional Facility log

    Examples:
    main_folder_path = "path/to/main_folder"
    datalist = readthedata_from_multiple_folders(main_folder_path)

    """
    data = {}

    for subfolder in os.listdir(main_folder_path):
        subfolder_path = os.path.join(main_folder_path, subfolder)
        if os.path.isdir(subfolder_path):
            try:
                # Construct file paths
                personfile = os.path.join(subfolder_path, f'{subfolder}personlog.csv')
                relationfile = os.path.join(subfolder_path, f'{subfolder}relationlog.csv')
                eventfile = os.path.join(subfolder_path, f'{subfolder}eventlog.csv')
                treatmentfile = os.path.join(subfolder_path, f'{subfolder}treatmentlog.csv')
                inputparamfile = os.path.join(subfolder_path, f'{subfolder}settingslog.csv')
                periodicfile = os.path.join(subfolder_path, f'{subfolder}periodiclog.csv')
                viralloadfile = os.path.join(subfolder_path, f'{subfolder}hivviralloadlog.csv')
                # facilitiesxyfile = os.path.join(subfolder_path, f'{subfolder}facilitypositions.csv')

                # Reading the CSV files into DataFrames
                ptable = pd.read_csv(personfile, low_memory=False)
                vltable = pd.read_csv(viralloadfile)
                rtable = pd.read_csv(relationfile)
                etable = pd.read_csv(eventfile, low_memory=False, header=None, names=list(range(14)))
                ttable = pd.read_csv(treatmentfile)
                itable = pd.read_csv(inputparamfile)

                # Naming columns in the event log DataFrame
                if etable.shape[1] == 10:
                    etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                                      "p1age", "p2name", "p2ID", "p2gender", "p2age"]
                elif etable.shape[1] == 12:
                    etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                                      "p1age", "p2name", "p2ID", "p2gender", "p2age",
                                      "extradescript", "value"]
                else:
                    etable.columns = ["eventtime", "eventname", "p1name", "p1ID", "p1gender",
                                      "p1age", "p2name", "p2ID", "p2gender", "p2age",
                                      "extradescript", "value", "relationage", "value1"]

                # Checking for existence of optional logs
                if os.path.exists(periodicfile):  # or os.path.exists(facilitiesxyfile):
                    ltable = pd.read_csv(periodicfile)
                    # ftable = pd.read_csv(facilitiesxyfile)
                    outputtables = {
                        'ptable': ptable,
                        'rtable': rtable,
                        'etable': etable,
                        'ttable': ttable,
                        'itable': itable,
                        'ltable': ltable,
                        'vltable': vltable
                        # 'ftable': ftable
                    }
                else:
                    outputtables = {
                        'ptable': ptable,
                        'rtable': rtable,
                        'etable': etable,
                        'ttable': ttable,
                        'itable': itable,
                        'vltable': vltable
                    }

                data[subfolder] = outputtables

            except FileNotFoundError as e:
                print(f"Error reading files from {subfolder_path}: {e}")

    return data

def input_params_creator(
        mortality_normal_weibull_shape=5,
        mortality_normal_weibull_scale=65,
        mortality_normal_weibull_genderdiff=0,
        periodiclogging_interval=1,
        syncrefyear_interval=1,
        formation_hazard_type="agegapry",
        person_art_accept_threshold_dist_type="fixed",
        person_art_accept_threshold_dist_fixed_value=0.5,
        person_eagerness_man_type="independent",
        person_eagerness_woman_type="independent",
        person_eagerness_man_dist_type="gamma",
        person_eagerness_woman_dist_type="gamma",
        person_eagerness_man_dist_gamma_a=0.231989836885,  # 0.15#0.85#0.1
        person_eagerness_man_dist_gamma_b=45,  # 70#100#3.5#5#10#20 #170
        person_eagerness_woman_dist_gamma_a=0.231989836885,  # 0.15#0.1
        person_eagerness_woman_dist_gamma_b=45,  # 70#100#3.5#5#10#20#170
        person_agegap_man_dist_type="normal",
        person_agegap_woman_dist_type="normal",
        person_agegap_man_dist_normal_mu=0,  # -5
        person_agegap_woman_dist_normal_mu=0,  # 2.5
        person_agegap_man_dist_normal_sigma=1,
        person_agegap_woman_dist_normal_sigma=1,
        formation_hazard_agegapry_numrel_man=-0.5,
        formation_hazard_agegapry_numrel_woman=-0.5,
        formation_hazard_agegapry_gap_factor_man_exp=-0.35,  # -0.15#-0.5
        formation_hazard_agegapry_gap_factor_woman_exp=-0.35,  # -0.15
        formation_hazard_agegapry_gap_factor_man_age=0.05,
        formation_hazard_agegapry_gap_factor_woman_age=0.05,
        formation_hazard_agegapry_meanage=-0.1,
        formation_hazard_agegapry_numrel_diff=-0.1,
        formation_hazard_agegapry_gap_factor_man_const=0,
        formation_hazard_agegapry_gap_factor_woman_const=0,
        formation_hazard_agegapry_gap_agescale_man=0.23,
        formation_hazard_agegapry_gap_agescale_woman=0.1,  # 0.23
        formation_hazard_agegapry_eagerness_sum=0.1,
        person_vsp_tofinalaids_x=12,
        person_vsp_toaids_x=7,
        formation_hazard_agegapry_eagerness_diff=-0.048,  # -0.110975
        dissolution_alpha_0=-0.52,  # -0.1 # baseline
        dissolution_alpha_4=-0.05,
        debut_debutage=15,
        population_simtime=40,
        population_nummen=500,  # 1000 #2000
        population_numwomen=500,  # 1000 #2000
        population_eyecap_fraction=0.2,
        hivseed_type="amount",
        hivseed_amount=20,
        hivseed_age_min=20,
        hivseed_age_max=30,
        hivseed_time=10,
        hivtransmission_param_a=-1.0352239,
        hivtransmission_param_b=-89.339994,
        hivtransmission_param_c=0.4948478,
        hivtransmission_param_f1=np.log(5),  # ~1.6 =>hazard is x5 in 15yo
        hivtransmission_param_f2=np.log(np.log(2.5) / np.log(5)) / 5,
        mortality_aids_survtime_C=62,
        mortality_aids_survtime_k=-0.2,
        conception_alpha_base=-2.35,  # -3
        diagnosis_baseline=-100,
        monitoring_cd4_threshold=0.1,  # Treatment will not start before schedule
        monitoring_fraction_log_viralload=0.3,
        population_msm="no",
        person_eagerness_man_msm_dist_type="fixed",
        person_eagerness_man_msm_dist_fixed_value=0,
        formationmsm_hazard_type="simple",
        formationmsm_hazard_simple_alpha_0=2,
        formationmsm_hazard_simple_alpha_12=-0.4,
        formationmsm_hazard_simple_alpha_5=-0.2,  # The factor (alpha) 5 controls the relative importance of the age gap between the partners.
        formationmsm_hazard_simple_alpha_6=0,  # weight for sum of eagerness parameters
        formationmsm_hazard_simple_alpha_7=0,
        birth_pregnancyduration_dist_type="fixed",
        birth_pregnancyduration_dist_fixed_value=268/365,  # just over 38 weeks
        birth_boygirlratio=1.0/2.01,  # 0.5024876, #101:100
        dropout_interval_dist_type="exponential"  # ,
        # dropout_interval_dist_exponential_lambda = 0.1 # ~ 18% dropout after 2 year
        # monitoring_cd4_threshold_instudy_transitionstage = Inf,
        # monitoring_cd4_threshold_instudy_interventionstage = Inf
):
    input_params = {}
    input_params["mortality.normal.weibull.shape"] = mortality_normal_weibull_shape
    input_params["mortality.normal.weibull.scale"] = mortality_normal_weibull_scale
    input_params["mortality.normal.weibull.genderdiff"] = mortality_normal_weibull_genderdiff
    input_params["periodiclogging.interval"] = periodiclogging_interval
    input_params["syncrefyear.interval"] = syncrefyear_interval
    input_params["formation.hazard.type"] = formation_hazard_type
    input_params["person.art.accept.threshold.dist.type"] = person_art_accept_threshold_dist_type
    input_params["person.art.accept.threshold.dist.fixed.value"] = person_art_accept_threshold_dist_fixed_value
    input_params["person.eagerness.man.type"] = person_eagerness_man_type
    input_params["person.eagerness.woman.type"] = person_eagerness_woman_type
    input_params["person.eagerness.man.dist.type"] = person_eagerness_man_dist_type
    input_params["person.eagerness.woman.dist.type"] = person_eagerness_woman_dist_type
    input_params["person.eagerness.man.dist.gamma.a"] = person_eagerness_man_dist_gamma_a
    input_params["person.eagerness.man.dist.gamma.b"] = person_eagerness_man_dist_gamma_b
    input_params["person.eagerness.woman.dist.gamma.a"] = person_eagerness_woman_dist_gamma_a
    input_params["person.eagerness.woman.dist.gamma.b"] = person_eagerness_woman_dist_gamma_b
    input_params["person.agegap.man.dist.type"] = person_agegap_man_dist_type
    input_params["person.agegap.woman.dist.type"] = person_agegap_woman_dist_type
    input_params["person.agegap.man.dist.normal.mu"] = person_agegap_man_dist_normal_mu
    input_params["person.agegap.woman.dist.normal.mu"] = person_agegap_woman_dist_normal_mu
    input_params["person.agegap.man.dist.normal.sigma"] = person_agegap_man_dist_normal_sigma
    input_params["person.agegap.woman.dist.normal.sigma"] = person_agegap_woman_dist_normal_sigma
    input_params["formation.hazard.agegapry.numrel_man"] = formation_hazard_agegapry_numrel_man
    input_params["formation.hazard.agegapry.numrel_diff"] = formation_hazard_agegapry_numrel_diff
    input_params["formation.hazard.agegapry.numrel_woman"] = formation_hazard_agegapry_numrel_woman
    input_params["formation.hazard.agegapry.gap_factor_man_age"] = formation_hazard_agegapry_gap_factor_man_age
    input_params["formation.hazard.agegapry.gap_factor_woman_age"] = formation_hazard_agegapry_gap_factor_woman_age
    input_params["formation.hazard.agegapry.meanage"] = formation_hazard_agegapry_meanage
    input_params["formation.hazard.agegapry.gap_factor_man_exp"] = formation_hazard_agegapry_gap_factor_man_exp
    input_params["formation.hazard.agegapry.gap_factor_woman_exp"] = formation_hazard_agegapry_gap_factor_woman_exp
    input_params["formation.hazard.agegapry.gap_factor_man_const"] = formation_hazard_agegapry_gap_factor_man_const
    input_params["formation.hazard.agegapry.gap_factor_woman_const"] = formation_hazard_agegapry_gap_factor_woman_const
    input_params["formation.hazard.agegapry.gap_agescale_man"] = formation_hazard_agegapry_gap_agescale_man
    input_params["formation.hazard.agegapry.gap_agescale_woman"] = formation_hazard_agegapry_gap_agescale_woman
    input_params["formation.hazard.agegapry.eagerness_sum"] = formation_hazard_agegapry_eagerness_sum
    input_params["formation.hazard.agegapry.eagerness_diff"] = formation_hazard_agegapry_eagerness_diff
    input_params["dissolution.alpha_0"] = dissolution_alpha_0
    input_params["dissolution.alpha_4"] = dissolution_alpha_4
    input_params["debut.debutage"] = debut_debutage
    input_params["population.simtime"] = population_simtime
    input_params["population.nummen"] = population_nummen
    input_params["population.numwomen"] = population_numwomen
    input_params["population.eyecap.fraction"] = population_eyecap_fraction
    input_params["hivseed.type"] = hivseed_type
    input_params["hivseed.amount"] = hivseed_amount
    input_params["hivseed.age.min"] = hivseed_age_min
    input_params["hivseed.age.max"] = hivseed_age_max
    input_params["hivseed.time"] = hivseed_time
    input_params["hivtransmission.param.a"] = hivtransmission_param_a
    input_params["hivtransmission.param.b"] = hivtransmission_param_b
    input_params["hivtransmission.param.c"] = hivtransmission_param_c
    input_params["hivtransmission.param.f1"] = hivtransmission_param_f1
    input_params["hivtransmission.param.f2"] = hivtransmission_param_f2
    input_params["mortality.aids.survtime.C"] = mortality_aids_survtime_C
    input_params["mortality.aids.survtime.k"] = mortality_aids_survtime_k
    input_params["conception.alpha_base"] = conception_alpha_base
    input_params["diagnosis.baseline"] = diagnosis_baseline
    input_params["monitoring.cd4.threshold"] = monitoring_cd4_threshold
    input_params["monitoring.fraction.log_viralload"] = monitoring_fraction_log_viralload
    input_params["population.msm"] = population_msm
    input_params["person.eagerness.man.msm.dist.type"] = person_eagerness_man_msm_dist_type
    input_params["person.eagerness.man.msm.dist.fixed.value"] = person_eagerness_man_msm_dist_fixed_value
    input_params["formationmsm.hazard.type"] = formationmsm_hazard_type
    input_params["formationmsm.hazard.simple.alpha_0"] = formationmsm_hazard_simple_alpha_0
    input_params["formationmsm.hazard.simple.alpha_12"] = formationmsm_hazard_simple_alpha_12
    input_params["formationmsm.hazard.simple.alpha_5"] = formationmsm_hazard_simple_alpha_5
    input_params["formationmsm.hazard.simple.alpha_6"] = formationmsm_hazard_simple_alpha_6
    input_params["formationmsm.hazard.simple.alpha_7"] = formationmsm_hazard_simple_alpha_7
    input_params["birth.pregnancyduration.dist.type"] = birth_pregnancyduration_dist_type
    input_params["birth.pregnancyduration.dist.fixed.value"] = birth_pregnancyduration_dist_fixed_value
    input_params["birth.boygirlratio"] = birth_boygirlratio
    input_params["dropout.interval.dist.type"] = dropout_interval_dist_type
    # input_params["dropout.interval.dist.exponential.lambda"] = dropout_interval_dist_exponential_lambda
    # input_params["monitoring.cd4.threshold.instudy.transitionstage"] = monitoring_cd4_threshold_instudy_transitionstage
    # input_params["monitoring.cd4.threshold.instudy.interventionstage"] = monitoring_cd4_threshold_instudy_interventionstage

    return input_params

def agedistr_creator(shape=5, scale=65):
    """
    Create an age distribution for the population at the start of the simulation.

    Create an age distribution, consistent with a Weibull survival distribution in
    the absence of HIV-related mortality, for the population at the start of the simulation.

    Parameters:
    shape (float): The shape parameter for the Weibull distribution function (default is 5).
    scale (float): The scale parameter for the Weibull distribution function (default is 65).

    Returns:
    pandas.DataFrame: A data frame with Age, Percent_Male and Percent_Female as variables, 
                      and 101 rows (0.5 to 100.5 years old). Nobody gets older than 100 years old.

    Examples:
    >>> agedist_data_frame = agedistr_creator(shape=5, scale=65)
    >>> agedist_data_frame
    """
    agebins = np.arange(1, 100, 1)
    probofstillalive = 1 - weibull_min.cdf(agebins, c=shape, scale=scale)
    fractionsinagebins = 100 * probofstillalive / np.sum(probofstillalive)
    
    agedist_data_frame = pd.DataFrame({
        'Age': np.append(agebins, 100),
        'Percent_Male': np.append(fractionsinagebins, 0),
        'Percent_Female': np.append(fractionsinagebins, 0)
    })
    
    return agedist_data_frame

def pop_growth_calculator(datalist, timewindow):
    """
    Calculate population growth rate.

    Calculate the growth rate of the entire population, averaged over a particular time window.

    Parameters:
    datalist (dict): The dictionary containing the data produced by reading the data.
                     It should contain keys 'ltable' and 'itable' as specified.
    timewindow (list): Boundaries of the time window (lower bound < time <= upper bound) that
                       should be retained, e.g., [20, 30].

    Returns:
    float: Population growth rate estimate for the specified time window.

    Examples:
    >>> data = readthedata()
    >>> growth_rate = pop_growth_calculator(datalist=data, timewindow=[0, 20])
    >>> growth_rate
    """
    end_popsize = datalist['ltable'].loc[datalist['ltable']['Time'] == timewindow[1], 'PopSize'].values[0]

    if timewindow[0] == 0:
        start_popsize = datalist['itable']['population.nummen'] + datalist['itable']['population.numwomen']
    else:
        start_popsize = datalist['ltable'].loc[datalist['ltable']['Time'] == timewindow[0], 'PopSize'].values[0]

    growth_rate = np.log(end_popsize / start_popsize) / np.diff(timewindow)

    return float(growth_rate[0])

def proportion_diagnosed_calculator(datalist, agegroup, timepoint):
    # Subset data to include only those alive and infected at the specified timepoint

    df_alive_infected_diagnosed = alive_diagnosed(datalist=datalist, timepoint=timepoint)

    # Retain only those who are in the specified age groups
    df_alive_infected_diagnosed = df_alive_infected_diagnosed[
        (timepoint - df_alive_infected_diagnosed['TOB'] >= agegroup[0]) &
        (timepoint - df_alive_infected_diagnosed['TOB'] < agegroup[1])
    ]

    if not df_alive_infected_diagnosed.empty:
        # Create summary table of prevalence by gender
        prevalence_df = df_alive_infected_diagnosed.groupby('Gender').agg(
            popsize=('TOB', 'size'),  # Total observations for each gender
            sum_cases=('Infected', 'sum'),  # Total cases for each gender
            sum_diagnosed=('Diagnosed', 'sum')
        ).reset_index()

        # Check for missing genders
        missing_genders = [gender for gender in [0, 1] if gender not in prevalence_df['Gender'].values]

        # Add missing genders with NaN values
        for gender in missing_genders:
            prevalence_df = pd.concat([prevalence_df, pd.DataFrame({'Gender': [gender], 'popsize': [np.nan], 'sum_cases': [np.nan]})], ignore_index=True)

        # Sort by Gender for readability
        prevalence_df = prevalence_df.sort_values(by='Gender').reset_index(drop=True)

        # Calculate point prevalence and confidence intervals       
        # Ensure we handle division by zero
        prevalence_df['propdiagnosed'] = np.where(prevalence_df['sum_cases'] != 0,
                                                prevalence_df['sum_diagnosed'] / prevalence_df['sum_cases'],
                                                np.nan)
        prevalence_df['pointprevalence'] = prevalence_df['sum_cases'] / prevalence_df['popsize']
        

        lower_bounds_1 = []
        upper_bounds_2 = []
        
        for index, row in prevalence_df.iterrows():
            if not np.isnan(row['sum_cases']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_cases']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds_1.append(ci.low)
                upper_bounds_2.append(ci.high)
            else:
                lower_bounds_1.append(np.nan)
                upper_bounds_2.append(np.nan)

        prevalence_df['pointprevalence.95.ll'] = lower_bounds_1
        prevalence_df['pointprevalence.95.ul'] = upper_bounds_2

        # Calculate overall prevalence
        prevalence_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [df_alive_infected_diagnosed.shape[0]],
            'sum_cases': [df_alive_infected_diagnosed['Infected'].sum()],
            'sum_diagnosed' :  [df_alive_infected_diagnosed['Diagnosed'].sum()]
        })

        prevalence_all_df['propdiagnosed'] = np.where(prevalence_all_df['sum_cases'] != 0,
                                        prevalence_all_df['sum_diagnosed'] / prevalence_all_df['sum_cases'],
                                        np.nan)
        prevalence_all_df['pointprevalence'] = prevalence_all_df['sum_cases'] / prevalence_all_df['popsize']

        # Calculate confidence intervals for overall prevalence

        lower_bounds = []
        upper_bounds = []
        
        for index, row in prevalence_all_df.iterrows():
            if not np.isnan(row['sum_cases']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_cases']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds.append(ci.low)
                upper_bounds.append(ci.high)
            else:
                lower_bounds.append(np.nan)
                upper_bounds.append(np.nan)

        prevalence_all_df['pointprevalence.95.ll'] = lower_bounds
        prevalence_all_df['pointprevalence.95.ul'] = upper_bounds

        # Combine stratified and overall prevalence data frames
        prevalence_df = pd.concat([prevalence_df, prevalence_all_df], ignore_index=True)

    else:
        # In case there are no observations in the specified age group
        prevalence_df = pd.DataFrame({
            'Gender': [np.nan, np.nan, np.nan],
            'popsize': [np.nan, np.nan, np.nan],
            'sum_cases': [np.nan, np.nan, np.nan],
            'sum_diagnosed':[np.nan, np.nan, np.nan],
            'propdiagnosed':[np.nan, np.nan, np.nan],
            'pointprevalence': [np.nan, np.nan, np.nan],
            'pointprevalence.95.ll': [np.nan, np.nan, np.nan],
            'pointprevalence.95.ul': [np.nan, np.nan, np.nan]
        })
    return prevalence_df

def prevalence_calculator(datalist, agegroup, timepoint):
    """
    Calculate HIV prevalence, overall and stratified.

    Produces a data frame that contains the overall and gender-stratified HIV prevalence
    at a specified point in simulation time and for a specific age group.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    agegroup (list): Boundaries of the age group (lower bound <= age < upper bound)
                     that should be retained. Should be expressed as a list of two integers.
                     e.g., [15, 30].
    timepoint (int): Point in simulation time at which HIV prevalence should be calculated.

    Returns:
    pandas.DataFrame: A data frame with prevalence estimate and surrounding confidence
                      bounds, for the specified time point and age group, overall, and
                      stratified by gender.

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    prev_df = prevalence_calculator(datalist=dl, agegroup=[15, 30], timepoint=30)
    prev_df
    """

    # Subset data to include only those alive and infected at the specified timepoint
    df_alive_infect = alive_infected(datalist=datalist, timepoint=timepoint)

    # Retain only those who are in the specified age groups
    df_alive_infect = df_alive_infect[
        (timepoint - df_alive_infect['TOB'] >= agegroup[0]) &
        (timepoint - df_alive_infect['TOB'] < agegroup[1])
    ]

    if not df_alive_infect.empty:
        # Create summary table of prevalence by gender
        prevalence_df = df_alive_infect.groupby('Gender').agg(
            popsize=('TOB', 'size'),  # Total observations for each gender
            sum_cases=('Infected', 'sum')  # Total cases for each gender
        ).reset_index()

        # Check for missing genders
        missing_genders = [gender for gender in [0, 1] if gender not in prevalence_df['Gender'].values]

        # Add missing genders with NaN values
        for gender in missing_genders:
            prevalence_df = pd.concat([prevalence_df, pd.DataFrame({'Gender': [gender], 'popsize': [np.nan], 'sum_cases': [np.nan]})], ignore_index=True)

        # Sort by Gender for readability
        prevalence_df = prevalence_df.sort_values(by='Gender').reset_index(drop=True)

        # Calculate point prevalence and confidence intervals
        prevalence_df['pointprevalence'] = prevalence_df['sum_cases'] / prevalence_df['popsize']

        lower_bounds_1 = []
        upper_bounds_2 = []
        
        for index, row in prevalence_df.iterrows():
            if not np.isnan(row['sum_cases']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_cases']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds_1.append(ci.low)
                upper_bounds_2.append(ci.high)
            else:
                lower_bounds_1.append(np.nan)
                upper_bounds_2.append(np.nan)

        prevalence_df['pointprevalence.95.ll'] = lower_bounds_1
        prevalence_df['pointprevalence.95.ul'] = upper_bounds_2

        # Calculate overall prevalence
        prevalence_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [df_alive_infect.shape[0]],
            'sum_cases': [df_alive_infect['Infected'].sum()],
            'pointprevalence': [df_alive_infect['Infected'].sum() / df_alive_infect.shape[0]]
        })

        # Calculate confidence intervals for overall prevalence

        lower_bounds = []
        upper_bounds = []
        
        for index, row in prevalence_all_df.iterrows():
            if not np.isnan(row['sum_cases']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_cases']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds.append(ci.low)
                upper_bounds.append(ci.high)
            else:
                lower_bounds.append(np.nan)
                upper_bounds.append(np.nan)

        prevalence_all_df['pointprevalence.95.ll'] = lower_bounds
        prevalence_all_df['pointprevalence.95.ul'] = upper_bounds

        # Combine stratified and overall prevalence data frames
        prevalence_df = pd.concat([prevalence_df, prevalence_all_df], ignore_index=True)

    else:
        # In case there are no observations in the specified age group
        prevalence_df = pd.DataFrame({
            'Gender': [np.nan, np.nan, np.nan],
            'popsize': [np.nan, np.nan, np.nan],
            'sum_cases': [np.nan, np.nan, np.nan],
            'pointprevalence': [np.nan, np.nan, np.nan],
            'pointprevalence.95.ll': [np.nan, np.nan, np.nan],
            'pointprevalence.95.ul': [np.nan, np.nan, np.nan]
        })

    return prevalence_df

def ART_coverage_calculator(datalist, agegroup, timepoint, site="All"):
    """
    Calculate overall HIV prevalence and ART coverage aggregated by gender.

    Calculate the HIV prevalence and ART coverage at a point in time, for specific
    age groups and gender strata.

    Parameters:
    datalist (dict): The dictionary object that is produced by readthedata.
    agegroup (list): Boundaries of the age group (lower.bound <= age < upper.bound) that
                    should be retained, e.g. agegroup = [15, 30]
    timepoint (int): Point in time at which the ART coverage should be calculated.
    site (str): Select only the particular site from the study, if all ignore site/use all sites.
                Default is "All".

    Returns:
    pandas.DataFrame: A dataframe with HIV prevalence estimates and ART coverage estimates and
                      surrounding confidence bounds,
                      for the specified time point and age group, overall, and stratified by gender.

    Examples:
    data(datalist)
    ART_coverage_df = ART_coverage_calculator(datalist=datalist, agegroup=[15, 30], timepoint=30, site="All")
    ART_coverage_df
    """

    # First, filter people who were alive and infected at the timepoint
    
    df_alive_infected = alive_infected(datalist=datalist, timepoint=timepoint)
    #df_alive_infected = df_alive_infected[df_alive_infected['Infected']]

    # Filter by age group
    alive_infected_agegroup = df_alive_infected[(df_alive_infected['TOB'] <= timepoint - agegroup[0]) &
                                             (df_alive_infected['TOB'] > timepoint - agegroup[1])]

    raw_df = alive_infected_agegroup.copy()

    # Filter ART data to get those on ART at the timepoint
    art_df = datalist['ttable'][(datalist['ttable']['TStart'].astype(float) <= timepoint) &
                                (datalist['ttable']['TEnd'].astype(float) > timepoint)]

    # Merge ART status into raw_df
    raw_df = pd.merge(raw_df, art_df, on=['ID', 'Gender'], how='left')

    if not raw_df.empty and raw_df['Infected'].sum() > 0:
        raw_df['onART'] = ~raw_df['TStart'].isna()

        ART_coverage_df = raw_df.groupby('Gender').agg(
            popsize=('Gender', 'size'),
            sum_cases=('Infected', 'sum'),
            sum_onART=('onART', 'sum')
            ).reset_index()

        lower_bounds_prev = []
        upper_bounds_prev = []
        lower_bounds_ART = []
        upper_bounds_ART = []

        for index, row in ART_coverage_df.iterrows():
            if not np.isnan(row['sum_cases']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result_prev = binomtest(int(row['sum_cases']), int(row['popsize']))
                ci_prev = result_prev.proportion_ci(confidence_level=0.95)
                lower_bounds_prev.append(ci_prev.low)
                upper_bounds_prev.append(ci_prev.high)
            else:
                lower_bounds_prev.append(np.nan)
                upper_bounds_prev.append(np.nan)

        for index, row in ART_coverage_df.iterrows():
            if not np.isnan(row['sum_onART']) and not np.isnan(row['sum_cases']) and row['sum_cases'] >= 1:    
                result_ART = binomtest(int(row['sum_onART']), int(row['sum_cases']))
                ci_ART = result_ART.proportion_ci(confidence_level=0.95)
                lower_bounds_ART.append(ci_ART.low)
                upper_bounds_ART.append(ci_ART.high)
            else:
                lower_bounds_ART.append(np.nan)
                upper_bounds_ART.append(np.nan)

        ART_coverage_df['pointprevalence'] = ART_coverage_df['sum_cases'] / ART_coverage_df['popsize']
        ART_coverage_df['pointprevalence_95_ll'] = lower_bounds_prev
        ART_coverage_df['pointprevalence_95_ul'] = upper_bounds_prev
        ART_coverage_df['ART_coverage'] = ART_coverage_df['sum_onART'] / ART_coverage_df['sum_cases']
        ART_coverage_df['ART_coverage_95_ll'] = lower_bounds_ART
        ART_coverage_df['ART_coverage_95_ul'] = upper_bounds_ART

    # Calculate overall coverage
        ART_coverage_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [raw_df.shape[0]],
            'sum_cases': [raw_df['Infected'].sum()],
            'sum_onART': [raw_df['onART'].sum()]
        })

        lower_bounds_prev = []
        upper_bounds_prev = []
        lower_bounds_ART = []
        upper_bounds_ART = []

        for index, row in ART_coverage_all_df.iterrows():
            if not np.isnan(row['sum_cases']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result_prev = binomtest(int(row['sum_cases']), int(row['popsize']))
                ci_prev = result_prev.proportion_ci(confidence_level=0.95)
                lower_bounds_prev.append(ci_prev.low)
                upper_bounds_prev.append(ci_prev.high)
            else:
                lower_bounds_prev.append(np.nan)
                upper_bounds_prev.append(np.nan)

        for index, row in ART_coverage_all_df.iterrows():
            if not np.isnan(row['sum_onART']) and not np.isnan(row['sum_cases']) and row['sum_cases'] >= 1:    
                result_ART = binomtest(int(row['sum_onART']), int(row['sum_cases']))
                ci_ART = result_ART.proportion_ci(confidence_level=0.95)
                lower_bounds_ART.append(ci_ART.low)
                upper_bounds_ART.append(ci_ART.high)
            else:
                lower_bounds_ART.append(np.nan)
                upper_bounds_ART.append(np.nan)
        
        ART_coverage_all_df['pointprevalence'] = ART_coverage_all_df['sum_cases'] / ART_coverage_all_df['popsize']
        ART_coverage_all_df['pointprevalence_95_ll'] = lower_bounds_prev
        ART_coverage_all_df['pointprevalence_95_ul'] = upper_bounds_prev
        ART_coverage_all_df['ART_coverage'] = ART_coverage_all_df['sum_onART'] / ART_coverage_all_df['sum_cases']
        ART_coverage_all_df['ART_coverage_95_ll'] = lower_bounds_ART
        ART_coverage_all_df['ART_coverage_95_ul'] = upper_bounds_ART

        # Combine stratified and overall prevalence data frames
        ART_coverage_df = pd.concat([ART_coverage_df, ART_coverage_all_df], ignore_index=True)   
    
    else:
        ART_coverage_df = pd.DataFrame({
            'Gender': [None],
            'popsize': [None],
            'sum_cases': [None],
            'sum_onART': [None],
            'pointprevalence': [None],
            'pointprevalence_95_ll': [None],
            'pointprevalence_95_ul': [None],
            'ART_coverage': [None],
            'ART_coverage_95_ll': [None],
            'ART_coverage_95_ul': [None]
        })

    return ART_coverage_df

def population_calculator(datalist, agegroup, timepoint):
    """
    Calculate number of men and women at a given time point.

    Produces a data frame that contains the overall vmmc circumcised
    at a specified point in simulation time and for a specific age group.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    agegroup (list): Boundaries of the age group (lower bound <= age < upper bound)
                     that should be retained. Should be expressed as a list of two integers.
                     e.g., [15, 30].
    timepoint (int): Point in simulation time at which population size should be calculated.

    Returns:
    pandas.DataFrame: A data frame with prevalence estimate and surrounding confidence
                      bounds, for the specified time point and age group

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    pop_df = population_calculator(datalist=dl, agegroup=[15, 30], timepoint=30)
    pop_df
    """

    # Use personlog from the datalist
    df = datalist['ptable']

    # Check if a specific site has been specified
    df_alive = df[
            (df['TOB'].astype(float) <= timepoint) &             # Keep those born before or at timepoint
            (df['TOD'].astype(float) > timepoint)                # Keep those died after timepoint
        ].copy()


    # Retain only those who are in the specified age groups
    df_alive = df_alive[
        (timepoint - df_alive['TOB'] >= agegroup[0]) &
        (timepoint - df_alive['TOB'] < agegroup[1])
    ]

    if not df_alive.empty:
        # Create summary table of prevalence by gender
        population_df = df_alive.groupby('Gender').agg(
            popsize=('TOB', 'size')  # Total pop for each gender
        ).reset_index()

        # Check for missing genders
        missing_genders = [gender for gender in [0, 1] if gender not in population_df['Gender'].values]

        # Add missing genders with NaN values
        for gender in missing_genders:
            population_df = pd.concat([population_df, pd.DataFrame({'Gender': [gender], 'popsize': [np.nan]})], ignore_index=True)

        # Sort by Gender for readability
        population_df = population_df.sort_values(by='Gender').reset_index(drop=True)

        # Calculate overall prevalence
        population_df_ = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [df_alive.shape[0]]
        })

        # Combine stratified and overall prevalence data frames
        population_all_df = pd.concat([population_df, population_df_], ignore_index=True)

    else:
        # In case there are no observations in the specified age group
        population_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [np.nan]
        })

    return population_all_df

def alive_circumcised(datalist, timepoint):
    """
    Subset people alive at a point in time and add their VMMC status.

    Produces a data frame that contains persons from the simulation that were
    alive at a specified point in time. The new data frame also contains a
    variable that indicates whether or not the person was Circumcised at
    that point in time.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    timepoint (int): Point in time at which the subset should be created and HIV 
                     status should be evaluated.

    Returns:
    pandas.DataFrame: A data frame that contains a newly generated variable called
                      "Infected" that records the HIV status of persons at the time 
                      point indicated.

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    alive_at_twenty_df = alive_circumcised(datalist=dl, timepoint=20)
    """

    # Use personlog from the datalist
    df = datalist['ptable']

    df_alive = df[
        (df['TOB'].astype(float) <= timepoint) &             # Keep those born before or at timepoint
        (df['TOD'].astype(float) > timepoint)  &              # Keep those died after timepoint
        (df['Gender'] == 0) # Gender is male
    ].copy()
    
    df_alive = df_alive.reset_index(drop=True)

    events = datalist['etable']
    VMMC_events = events[events['eventname'] == '(VMMC_treatment)']
    VMMC_events = VMMC_events[['eventtime','p1ID', 'p1gender']]
    
    # Select only the relevant events.
    VMMC_events = VMMC_events[VMMC_events['eventtime'] <= timepoint]
    
    # Merge DataFrames on both id and gender
    merged_df = df_alive.merge(VMMC_events, left_on=['ID', 'Gender'], right_on=['p1ID', 'p1gender'], how='left', indicator=True)


    # Allocate infection status to all alive people in our table
    df_alive.loc[:,'Circumcised'] = merged_df['_merge'] == 'both'

    return df_alive

def vmmc_calculator(datalist, agegroup, timepoint):
    """
    Calculate vmmc percentage.

    Produces a data frame that contains the overall vmmc circumcised
    at a specified point in simulation time and for a specific age group.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    agegroup (list): Boundaries of the age group (lower bound <= age < upper bound)
                     that should be retained. Should be expressed as a list of two integers.
                     e.g., [15, 30].
    timepoint (int): Point in simulation time at which HIV prevalence should be calculated.

    Returns:
    pandas.DataFrame: A data frame with prevalence estimate and surrounding confidence
                      bounds, for the specified time point and age group

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    vmmc_df = vmmc_calculator(datalist=dl, agegroup=[15, 30], timepoint=30)
    vmmc_df
    """

    # Subset data to include only those alive and infected at the specified timepoint
    df_alive_circumcised = alive_circumcised(datalist=datalist, timepoint=timepoint)

    # Retain only those who are in the specified age groups
    df_alive_circumcised = df_alive_circumcised[
        (timepoint - df_alive_circumcised['TOB'] >= agegroup[0]) &
        (timepoint - df_alive_circumcised['TOB'] < agegroup[1])
    ]

    if not df_alive_circumcised.empty:

        # Calculate overall prevalence
        vmmc_prevalence_all_df = pd.DataFrame({
            'Gender': ['Male'],
            'popsize': [df_alive_circumcised.shape[0]],
            'sum_circumcised': [df_alive_circumcised['Circumcised'].sum()],
            'vmmcprevalence': [df_alive_circumcised['Circumcised'].sum() / df_alive_circumcised.shape[0]]
        })

        # Calculate confidence intervals for overall prevalence

        lower_bounds = []
        upper_bounds = []
        
        for index, row in vmmc_prevalence_all_df.iterrows():
            if not np.isnan(row['sum_circumcised']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_circumcised']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds.append(ci.low)
                upper_bounds.append(ci.high)
            else:
                lower_bounds.append(np.nan)
                upper_bounds.append(np.nan)

        vmmc_prevalence_all_df['vmmcprevalence.95.ll'] = lower_bounds
        vmmc_prevalence_all_df['vmmcprevalence.95.ul'] = upper_bounds

    else:
        # In case there are no observations in the specified age group
        vmmc_prevalence_all_df = pd.DataFrame({
            'Gender': ['Male'],
            'popsize': [np.nan],
            'sum_circumcised': [np.nan],
            'vmmcprevalence': [np.nan],
            'vmmcprevalence.95.ll': [np.nan],
            'vmmcprevalence.95.ul': [np.nan]
        })

    return vmmc_prevalence_all_df

def condom_users_calculator(datalist, agegroup, timepoint):
    """
    Calculate condom users percentage.

    Produces a data frame that contains the overall, age stratified condom users
    at a specified point in simulation time and for a specific age group.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    agegroup (list): Boundaries of the age group (lower bound <= age < upper bound)
                     that should be retained. Should be expressed as a list of two integers.
                     e.g., [15, 30].
    timepoint (int): Point in simulation time at which condom use prevalence should be calculated.

    Returns:
    pandas.DataFrame: A data frame with prevalence estimate and surrounding confidence
                      bounds, for the specified time point and age group

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    condom_users_df = condom_users_calculator(datalist=dl, agegroup=[15, 30], timepoint=30)
    condom_users_df
    """

    # Subset data to include only those alive at the specified timepoint
    # Use personlog from the datalist
    df = datalist['ptable']

    # Check if a specific site has been specified
    df_alive = df[
            (df['TOB'].astype(float) <= timepoint) &             # Keep those born before or at timepoint
            (df['TOD'].astype(float) > timepoint)                # Keep those died after timepoint
        ].copy()


    # Retain only those who are in the specified age groups
    df_alive = df_alive[
        (timepoint - df_alive['TOB'] >= agegroup[0]) &
        (timepoint - df_alive['TOB'] < agegroup[1])
    ]

    df_alive = df_alive.reset_index(drop=True)

    events = datalist['etable']
    Condom_use_events = events[events['eventname'] == '(Condom_Programming)']

    # Select only the relevant columns from table2
    Condom_use_events = Condom_use_events[['p1ID', 'p1gender']]

    # Merge DataFrames on both id and gender
    merged_df = df_alive.merge(Condom_use_events, left_on=['ID', 'Gender'], right_on=['p1ID', 'p1gender'], how='left', indicator=True)

    # Allocate Condom Users status to all alive people in our table
    df_alive.loc[:,'Condom_users'] = merged_df['_merge'] == 'both'

    if not df_alive.empty:
        # Create summary table of prevalence by gender
        condom_users_prevalence_df = df_alive.groupby('Gender').agg(
            popsize=('TOB', 'size'),  # Total observations for each gender
            sum_condom_users=('Condom_users', 'sum')  # Total condom_users for each gender
        ).reset_index()

        # Check for missing genders
        missing_genders = [gender for gender in [0, 1] if gender not in condom_users_prevalence_df['Gender'].values]

        # Add missing genders with NaN values
        for gender in missing_genders:
            condom_users_prevalence_df = pd.concat([condom_users_prevalence_df, pd.DataFrame({'Gender': [gender], 'popsize': [np.nan], 'sum_condom_users': [np.nan]})], ignore_index=True)

        # Sort by Gender for readability
        condom_users_prevalence_df = condom_users_prevalence_df.sort_values(by='Gender').reset_index(drop=True)

        # Calculate point prevalence and confidence intervals
        condom_users_prevalence_df['condom_users_prevalence'] = condom_users_prevalence_df['sum_condom_users'] / condom_users_prevalence_df['popsize']

        lower_bounds_1 = []
        upper_bounds_2 = []
        
        for index, row in condom_users_prevalence_df.iterrows():
            if not np.isnan(row['sum_condom_users']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_condom_users']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds_1.append(ci.low)
                upper_bounds_2.append(ci.high)
            else:
                lower_bounds_1.append(np.nan)
                upper_bounds_2.append(np.nan)

        condom_users_prevalence_df['condom_users_prevalence.95.ll'] = lower_bounds_1
        condom_users_prevalence_df['condom_users_prevalence.95.ul'] = upper_bounds_2

        # Calculate overall prevalence
        condom_users_prevalence_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [df_alive.shape[0]],
            'sum_condom_users': [df_alive['Condom_users'].sum()],
            'condom_users_prevalence': [df_alive['Condom_users'].sum() / df_alive.shape[0]]
        })

        # Calculate confidence intervals for overall prevalence

        lower_bounds = []
        upper_bounds = []
        
        for index, row in condom_users_prevalence_all_df.iterrows():
            if not np.isnan(row['sum_condom_users']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_condom_users']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds.append(ci.low)
                upper_bounds.append(ci.high)
            else:
                lower_bounds.append(np.nan)
                upper_bounds.append(np.nan)

        condom_users_prevalence_all_df['condom_users_prevalence.95.ll'] = lower_bounds
        condom_users_prevalence_all_df['condom_users_prevalence.95.ul'] = upper_bounds

        # Combine stratified and overall prevalence data frames
        condom_users_prevalence_df = pd.concat([condom_users_prevalence_df, condom_users_prevalence_all_df], ignore_index=True)

    else:
        # In case there are no observations in the specified age group
        condom_users_prevalence_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [np.nan],
            'sum_condom_users': [np.nan],
            'condom_users_prevalence': [np.nan],
            'condom_users_prevalence.95.ll': [np.nan],
            'condom_users_prevalence.95.ul': [np.nan]
        })

    return condom_users_prevalence_df

def condom_using_formation_calculator(datalist, timewindow):
    df = datalist['rtable']

    lwr_time, upr_time = timewindow

    # Filter relationships within the time bounds   
    df = df[
        (df["FormTime"]  <= upr_time)
        & (df["FormTime"] >= lwr_time)
    ].copy()

    if not df.empty:
    # Calculate overall prevalence
        condom_using_formation_prevalence_df = pd.DataFrame({
            'num_formations': [df.shape[0]],
            'condom_using_formations': [df['CondomUsingFormation'].sum()],
            'condom_using_formations_prevalence': [df['CondomUsingFormation'].sum() / df.shape[0]]
        })

        # Calculate confidence intervals for overall prevalence

        lower_bounds = []
        upper_bounds = []
        
        for index, row in condom_using_formation_prevalence_df.iterrows():
            if not np.isnan(row['condom_using_formations']) and not np.isnan(row['num_formations']) and row['num_formations'] >= 1:
                result = binomtest(int(row['condom_using_formations']), int(row['num_formations']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds.append(ci.low)
                upper_bounds.append(ci.high)
            else:
                lower_bounds.append(np.nan)
                upper_bounds.append(np.nan)

        condom_using_formation_prevalence_df['condom_using_formations_prevalence.95.ll'] = lower_bounds
        condom_using_formation_prevalence_df['condom_using_formations_prevalence.95.ul'] = upper_bounds

    else:
         condom_using_formation_prevalence_df = pd.DataFrame({
            'num_formations': [np.nan],
            'condom_using_formations': [np.nan],
            'condom_using_formations_prevalence': [np.nan],
            'condom_using_formations_prevalence.95.ll': [np.nan],
            'condom_using_formations_prevalence.95.ul': [np.nan]
        })
         
    return condom_using_formation_prevalence_df

def prep_users_calculator(datalist, agegroup, timewindow):
    """
    Calculate PrEP users percentage.

    Produces a data frame that contains the overall, age stratified prep users
    at a specified point in simulation time and for a specific age group.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    agegroup (list): Boundaries of the age group (lower bound <= age < upper bound)
                     that should be retained. Should be expressed as a list of two integers.
                     e.g., [15, 30].
    timewindow (int): Point in simulation time at which condom use prevalence should be calculated.

    Returns:
    pandas.DataFrame: A data frame with prevalence estimate and surrounding confidence
                      bounds, for the specified time window and age group

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    condom_users_df = prep_users_calculator(datalist=dl, agegroup=[15, 30], timewindow=[30,40])
    condom_users_df
    """

    # Subset data to include only those alive at the specified timepoint
    # Use personlog from the datalist
    df = datalist['ptable']

    lwr_time, upr_time = timewindow

    # Check those alive in that specified time window
    df_alive = df[
                (df['TOB'].astype(float) <= upr_time) &             # Keep those born before 
                (df['TOD'].astype(float) > upr_time)                # Keep those died after timepoint
            ].copy()

    # Retain only those who are in the specified age groups
    df_alive = df_alive[
            (lwr_time - df_alive['TOB'] >= agegroup[0]) &
            (upr_time - df_alive['TOB'] < agegroup[1])
        ]
    df_alive = df_alive.reset_index(drop=True)

    events = datalist['etable']
    prep_use_events = events[events['eventname'] == 'formation'] #change from formation to PrEP

    # Select only the relevant columns from table2
    prep_use_events = prep_use_events[['p1ID', 'p1gender']]

    # Merge DataFrames on both id and gender
    merged_df = df_alive.merge(prep_use_events, left_on=['ID', 'Gender'], right_on=['p1ID', 'p1gender'], how='left', indicator=True)

    # Allocate Prep status to all alive people in our table
    df_alive.loc[:,'Prep_user'] = merged_df['_merge'] == 'both'

    if not df_alive.empty:
        # Create summary table of prevalence by gender
        prep_users_prevalence_df = df_alive.groupby('Gender').agg(
            popsize=('TOB', 'size'),  # Total observations for each gender
            sum_prep_users=('Prep_user', 'sum')  # Total condom_users for each gender
        ).reset_index()

        # Check for missing genders
        missing_genders = [gender for gender in [0, 1] if gender not in prep_users_prevalence_df['Gender'].values]

        # Add missing genders with NaN values
        for gender in missing_genders:
            prep_users_prevalence_df = pd.concat([prep_users_prevalence_df, pd.DataFrame({'Gender': [gender], 'popsize': [np.nan], 'sum_prep_users': [np.nan]})], ignore_index=True)

        # Sort by Gender for readability
        prep_users_prevalence_df = prep_users_prevalence_df.sort_values(by='Gender').reset_index(drop=True)

        # Calculate point prevalence and confidence intervals
        prep_users_prevalence_df['prep_users_prevalence'] = prep_users_prevalence_df['sum_prep_users'] / prep_users_prevalence_df['popsize']

        lower_bounds_1 = []
        upper_bounds_2 = []
        
        for index, row in prep_users_prevalence_df.iterrows():
            if not np.isnan(row['sum_prep_users']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_prep_users']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds_1.append(ci.low)
                upper_bounds_2.append(ci.high)
            else:
                lower_bounds_1.append(np.nan)
                upper_bounds_2.append(np.nan)

        prep_users_prevalence_df['prep_users_prevalence.95.ll'] = lower_bounds_1
        prep_users_prevalence_df['prep_users_prevalence.95.ul'] = upper_bounds_2

        # Calculate overall prevalence
        prep_users_prevalence_df_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [df_alive.shape[0]],
            'sum_prep_users': [df_alive['Prep_user'].sum()],
            'prep_users_prevalence': [df_alive['Prep_user'].sum() / df_alive.shape[0]]
        })

        # Calculate confidence intervals for overall prevalence

        lower_bounds = []
        upper_bounds = []
        
        for index, row in prep_users_prevalence_df_all_df.iterrows():
            if not np.isnan(row['sum_prep_users']) and not np.isnan(row['popsize']) and row['popsize'] >= 1:
                result = binomtest(int(row['sum_prep_users']), int(row['popsize']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds.append(ci.low)
                upper_bounds.append(ci.high)
            else:
                lower_bounds.append(np.nan)
                upper_bounds.append(np.nan)

        prep_users_prevalence_df_all_df['prep_users_prevalence.95.ll'] = lower_bounds
        prep_users_prevalence_df_all_df['prep_users_prevalence.95.ul'] = upper_bounds

        # Combine stratified and overall prevalence data frames
        prep_users_prevalence_df = pd.concat([prep_users_prevalence_df, prep_users_prevalence_df_all_df], ignore_index=True)

    else:
        # In case there are no observations in the specified age group
        prep_users_prevalence_df = pd.DataFrame({
            'Gender': ['Total'],
            'popsize': [np.nan],
            'sum_prep_users': [np.nan],
            'prep_users_prevalence': [np.nan],
            'prep_users_prevalence.95.ll': [np.nan],
            'prep_users_prevalence.95.ul': [np.nan]
        })
    return prep_users_prevalence_df

def alive_infected(datalist, timepoint, site="All"):
    """
    Subset people alive at a point in time and add their HIV status.

    Produces a data frame that contains persons from the simulation that were
    alive at a specified point in time. The new data frame also contains a
    variable that indicates whether or not the person was infected with HIV at
    that point in time.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    timepoint (int): Point in time at which the subset should be created and HIV 
                     status should be evaluated.
    site (str): Users can specify a particular site they are interested in.
                The default is "All", which means that persons from all sites 
                should be included.

    Returns:
    pandas.DataFrame: A data frame that contains a newly generated variable called
                      "Infected" that records the HIV status of persons at the time 
                      point indicated.

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    alive_at_twenty_df = alive_infected(datalist=dl, timepoint=20)
    """

    # Use personlog from the datalist
    df = datalist['ptable']

    # Check if a specific site has been specified
    if site == "All":
        df_alive = df[
            (df['TOB'].astype(float) <= timepoint) &  # Keep those born before or at timepoint
            (df['TOD'].astype(float) > timepoint)     # Keep those died after timepoint
        ].copy()
    else:
        df_alive = df[
            (df['TOB'].astype(float) <= timepoint) &             # Keep those born before or at timepoint
            (df['TOD'].astype(float) > timepoint) &              # Keep those died after timepoint
            (df['pfacility'] == site)              # Keep those at the specified facility
        ].copy()

    # Allocate infection status to all alive people in our table
    df_alive['Infected'] = (timepoint >= df_alive['InfectTime'].astype(float))

    return df_alive

def alive_diagnosed(datalist, timepoint):
    """
    Subset people alive at a point in time and add their HIV status.

    Produces a data frame that contains persons from the simulation that were
    alive at a specified point in time. The new data frame also contains a
    variable that indicates whether or not the person was infected with HIV at
    that point in time.

    Parameters:
    datalist (dict): The dictionary object produced by readthedata.
    timepoint (int): Point in time at which the subset should be created and HIV 
                     status should be evaluated.
    site (str): Users can specify a particular site they are interested in.
                The default is "All", which means that persons from all sites 
                should be included.

    Returns:
    pandas.DataFrame: A data frame that contains a newly generated variable called
                      "Infected" that records the HIV status of persons at the time 
                      point indicated.

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    alive_at_twenty_df = alive_diagnosed(datalist=dl, timepoint=20)
    """

    # Use personlog from the datalist
    df = datalist['ptable']

    # Check if a specific site has been specified
    
    df_alive = df[
            (df['TOB'].astype(float) <= timepoint) &             # Keep those born before or at timepoint
            (df['TOD'].astype(float) > timepoint)         # Keep those at the specified facility
        ].copy()

    df_alive = df_alive.reset_index(drop=True)

    events = datalist['etable']
    diagnosis_events = events[events['eventname'] == 'diagnosis']

    # Select only the relevant columns from table2
    diagnosis_events = diagnosis_events[['eventtime','p1ID', 'p1gender']]

    diagnosis_events = diagnosis_events[diagnosis_events['eventtime'] <= timepoint]

    # lets get unique ids since people can be diagnosed more than once after they drop out
    # Find the index of the earliest eventtime for each combination of p1ID and p1gender
    idx = diagnosis_events.groupby(['p1ID', 'p1gender'])['eventtime'].idxmin()
    # Select those rows from the DataFrame
    unique_diagnosis_events = diagnosis_events.loc[idx]

    # Merge DataFrames on both id and gender
    merged_df = df_alive.merge(unique_diagnosis_events, left_on=['ID', 'Gender'], right_on=['p1ID', 'p1gender'], how='left', indicator=True)

    # Allocate Condom Users status to all alive people in our table
    df_alive.loc[:,'Diagnosed'] = merged_df['_merge'] == 'both'
    df_alive['Infected'] = (timepoint >= df_alive['InfectTime'].astype(float))

    return df_alive

def AIDS_deaths_calculator(datalist, agegroup, timepoint):
    # Use personlog from the datalist
    df = datalist['ptable']


    df_dead = df[
            (df['TOD'].astype(float) <= timepoint) 
        ].copy()

    AIDS_dead = df_dead[df_dead['AIDSDeath'] == 1].reset_index(drop=True)

    # Retain only those who are in the specified age groups
    AIDS_dead = AIDS_dead[
    (timepoint - AIDS_dead['TOB'] >= agegroup[0]) &
    (timepoint - AIDS_dead['TOB'] < agegroup[1])
    ]

    if not AIDS_dead.empty:
        # Create summary table of prevalence by gender
        AIDS_dead_df = AIDS_dead.groupby('Gender').agg(
            sum_AIDSDeath=('AIDSDeath', 'sum')  # Total cases for each gender
        ).reset_index()

        # Check for missing genders
        missing_genders = [gender for gender in [0, 1] if gender not in AIDS_dead_df['Gender'].values]

        # Add missing genders with NaN values
        for gender in missing_genders:
            AIDS_dead_df = pd.concat([AIDS_dead_df, pd.DataFrame({'Gender': [gender], 'sum_AIDSDeath': [np.nan]})], ignore_index=True)

        # Sort by Gender for readability
        AIDS_dead_df = AIDS_dead_df.sort_values(by='Gender').reset_index(drop=True)

        # Calculate overall deaths
        AIDS_dead_all_df = pd.DataFrame({
            'Gender': ['Total'],
            'sum_AIDSDeath': [AIDS_dead['AIDSDeath'].sum()]
        })

        # Combine stratified and overall prevalence data frames
        AIDS_dead_df = pd.concat([AIDS_dead_df, AIDS_dead_all_df], ignore_index=True)

    else:
        # In case there are no observations in the specified age group
        AIDS_dead_df = pd.DataFrame({
            'Gender': [np.nan, np.nan, np.nan],
            'sum_AIDSDeath': [np.nan, np.nan, np.nan]
        })

    return AIDS_dead_df

def VL_suppression_calculator(datalist, agegroup, timepoint, vl_cutoff=1000, site="All"):
    """
    Calculate viral suppression fraction.
    
    Calculate the fraction of HIV infected people of a particular age group who
    are virally suppressed at a point in time.
    
    Parameters:
    datalist (dict): The dictionary object that is produced by readthedata.
    agegroup (list): Boundaries of the age group (lower.bound <= age < upper.bound) that
                     should be retained, e.g. agegroup = [15, 30]
    timepoint (int): Point in time at which the viral suppression fraction should be calculated.
    vl_cutoff (int): Viral load below this threshold (e.g., <1000 copies/mL) is defined as suppressed.
    site (str): Select only the particular site from the study, if all ignore site/use all sites.
                Default is "All".
    
    Returns:
    pandas.DataFrame: A dataframe with VL suppression estimates and surrounding confidence
                      bounds, for the specified time point and age group, overall, and stratified by gender.
    
    Examples:
    data(datalist)
    VL_suppression_df = VL_suppression_calculator(datalist=datalist, agegroup=[15, 30], timepoint=30, vl_cutoff=1000, site="All")
    VL_suppression_df
    """
    
    # First, filter people who were alive and infected at the timepoint
    
    df_alive_infected = alive_infected(datalist=datalist, timepoint=timepoint)
    #df_alive_infected = df_alive_infected[df_alive_infected['Infected']]

    # Filter by age group
    alive_infected_agegroup = df_alive_infected[(df_alive_infected['TOB'] <= timepoint - agegroup[0]) &
                                             (df_alive_infected['TOB'] > timepoint - agegroup[1])]

    raw_df = alive_infected_agegroup.copy()

    # Filter ART data to get those on ART at the timepoint and Merge ART status into raw_df
    art_df = datalist['ttable'][(datalist['ttable']['TStart'].astype(float) <= timepoint) &
                                (datalist['ttable']['TEnd'].astype(float) > timepoint)]

    raw_df = pd.merge(raw_df, art_df, on=['ID', 'Gender'], how='left') 
    raw_df['onART'] = ~raw_df['TStart'].isna()
    raw_df = raw_df[raw_df['onART'] == True]
    
    # Get the most recent viral load (VL) for each person
    vl_df = datalist['vltable'][['Time', 'ID', 'Log10VL']]
    vl_df = vl_df[vl_df['Time'] <= timepoint]
    vl_df = vl_df.sort_values(by=['ID', 'Time']).groupby('ID').last().reset_index()
    
    # Merge VL status into raw_df
    raw_df = pd.merge(raw_df, vl_df, on='ID', how='left')
    
    if not raw_df.empty and raw_df['onART'].sum() > 0:
        raw_df['Gender'] = raw_df['Gender'].astype(str)
        raw_df['vl_suppr'] = raw_df['Log10VL'] < np.log10(vl_cutoff)
        
        # Calculate VL suppression fraction by gender
        VL_suppression_df = raw_df.groupby('Gender').agg(
            sum_onART=('onART', 'sum'),
            sum_vl_suppr=('vl_suppr', 'sum')
        ).reset_index()

        VL_suppression_df['vl_suppr_frac'] = VL_suppression_df['sum_vl_suppr']/VL_suppression_df['sum_onART']

        # Calculate confidence intervals for overall prevalence

        lower_bounds_vl = []
        upper_bounds_vl = []

        for index, row in VL_suppression_df.iterrows():
            if not np.isnan(row['sum_vl_suppr']) and not np.isnan(row['sum_onART']) and row['sum_onART'] >= 1 :
                result = binomtest(int(row['sum_vl_suppr']), int(row['sum_onART']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds_vl.append(ci.low)
                upper_bounds_vl.append(ci.high)
            else:
                lower_bounds_vl.append(np.nan)
                upper_bounds_vl.append(np.nan)

        VL_suppression_df['vl_suppr_frac_95_ll'] = lower_bounds_vl
        VL_suppression_df['vl_suppr_frac_95_ul'] = upper_bounds_vl
        
        # Calculate overall VL suppression fraction
        VL_suppression_all_df = pd.DataFrame({
                    'Gender': ['Total'],
                    'sum_onART': [raw_df['onART'].sum()],
                    'sum_vl_suppr': [raw_df['vl_suppr'].sum()],
                    'vl_suppr_frac': [raw_df['vl_suppr'].sum() / raw_df['onART'].sum()]
                })

        lower_bounds_vl_all = []
        upper_bounds_vl_all = []

        for index, row in VL_suppression_all_df.iterrows():
            if not np.isnan(row['sum_vl_suppr']) and not np.isnan(row['sum_onART']) and row['sum_onART'] >= 1 :
                result = binomtest(int(row['sum_vl_suppr']), int(row['sum_onART']))
                ci = result.proportion_ci(confidence_level=0.95)
                lower_bounds_vl_all.append(ci.low)
                upper_bounds_vl_all.append(ci.high)
            else:
                lower_bounds_vl_all.append(np.nan)
                upper_bounds_vl_all.append(np.nan)

        VL_suppression_all_df['vl_suppr_frac_95_ll'] = lower_bounds_vl_all
        VL_suppression_all_df['vl_suppr_frac_95_ul'] = upper_bounds_vl_all 

        VL_suppression_df = pd.concat([VL_suppression_df, VL_suppression_all_df], ignore_index=True)
    
    else:
        # In case there are no data
        VL_suppression_df = pd.DataFrame({
            'Gender': [None],
            'sum_onART': [None],
            'sum_vl_suppr': [None],
            'vl_suppr_frac': [None],
            'vl_suppr_frac_95_ll': [None],
            'vl_suppr_frac_95_ul': [None]
        })
    
    return VL_suppression_df

def timespentsingle_calculator_v1(datalist, agegroup, timewindow, type="Strict"):
    df = datalist["ptable"]
    events = datalist["etable"]

    # Define age and time window limits (Scalar values)
    lwr_age, upr_age = agegroup
    lwr_time, upr_time = timewindow

    # Filter persons table for women within the specified age and time bounds
    df = df[
        (df["Gender"] == 1)
        & ((df["TOB"] + lwr_age) <= upr_time)
        & ((df["TOB"] + upr_age) >= lwr_time)
    ]

    # Determine the period of exposure for each woman
    # Calculate naive exposure time
    # 1. Determine the time person is X yo
    # 2. Determine the time person is Y yo
    # 3. Their exposure starts whichever comes last: lwr bound age, or lwr window
    # 4. Their exposure ends whichever comes 1st: upr bound age, upr window, or
    # infected with HIV
    # 5. Subtract exposure start from exposure end

    df["time_lwr_agegroup"] = df["TOB"] + lwr_age
    df["time_upr_agegroup"] = df["TOB"] + upr_age
    df["exposure_start"] = np.maximum(df["time_lwr_agegroup"], lwr_time)
    df["exposure_end"] = np.minimum(df["time_upr_agegroup"], upr_time, df["InfectTime"])
    df["exposure_time"] = (df["exposure_end"] - df["exposure_start"]).clip(lower=0)

    # If the exposure time is negative, then they had no exposure during the
    # timewindow or agegroup of interest
    #   df2 <- df1 %>%
    # dplyr::mutate(had.exposure.time = exposure.time > 0,
    #               exposure.time = ifelse(exposure.time < 0,
    #                                      0,
    #                                      exposure.time))
    # If the exposure time is negative, then they had no exposure during the time window or age group of interest
    df["had_exposure_time"] = df["exposure_time"] > 0
    df["exposure_time"] = np.where(df["exposure_time"] < 0, 0, df["exposure_time"])

    # Filter events related to relationship changes for women
    rel_events = events[
        (events["eventname"].isin(["formation", "dissolution"]))
        & (events["p2gender"] == 1)
        & (events["p2ID"].isin(df["ID"]))
    ]

    # Process relationship events to calculate single periods
    rel_events.sort_values(by=["p2ID", "eventtime"], inplace=True)
    rel_events["change"] = np.where(rel_events["eventname"] == "formation", 1, -1)
    rel_events["num_rels"] = rel_events.groupby("p2ID")["change"].cumsum()

    # Identify periods when women are single
    single_periods = rel_events[
        (rel_events["num_rels"].shift(1) == 0) & (rel_events["num_rels"] == 1)
    ]
    single_periods["single_start"] = single_periods["eventtime"]
    single_periods["single_end"] = single_periods.groupby("p2ID")["eventtime"].shift(-1)
    single_periods["single_time"] = (
        single_periods["single_end"] - single_periods["single_start"]
    ).clip(lower=0)

    if type == "Harling":
        # For the "Harling" definition, adjust to full-year blocks
        single_periods["year_start"] = single_periods["single_start"].apply(np.floor)
        single_periods["year_end"] = single_periods["single_end"].apply(np.ceil)
        single_periods["harling_time"] = (
            single_periods["year_end"] - single_periods["year_start"]
        ).clip(lower=0)
        result = single_periods.groupby("p2ID")["harling_time"].sum().reset_index()
    else:
        # For the "Strict" definition, use exact calculated times
        result = single_periods.groupby("p2ID")["single_time"].sum().reset_index()

    result.columns = ["woman_ID", "sum_norels_timespent"]
    return result

def poisson_exact(cases, exposure):
    """Calculate Poisson exact 95% confidence intervals."""
    mean = cases / exposure
    ci_low = poisson.ppf(0.025, cases) / exposure
    ci_high = poisson.ppf(0.975, cases) / exposure
    return ci_low, ci_high

def timespentsingle_calculator(datalist, agegroup, timewindow, type="Strict"):
    """
    The function `timespentsingle_calculator` calculates the total time spent being single for women
    within specified age and time bounds based on relationship events data. The function allows for
    two types of calculations: "Strict" and "Harling", with different definitions for calculating the
    time spent single.

    :param datalist: The `datalist` parameter is expected to be a dictionary containing two keys:
    "ptable" and "etable". The "ptable" key should hold a DataFrame with information about persons,
    including columns like "Gender", "TOB" (time of birth), and "InfectTime"
    :param agegroup: The `agegroup` parameter in the `timespentsingle_calculator` function represents
    the age range of interest for filtering individuals. It is expected to be a tuple containing two
    values: the lower age limit and the upper age limit. For example, if you want to analyze individuals
    between the ages
    :param timewindow: The `timewindow` parameter in the `timespentsingle_calculator` function
    represents the time window within which the calculations are performed. It consists of two values,
    `lwr_time` and `upr_time`, which define the lower and upper bounds of the time window, respectively
    :param type: The `type` parameter in the `timespentsingle_calculator` function specifies the type of
    calculation to be performed. It can have two possible values: "Strict" or "Harling", defaults to
    Strict (optional)
    :return: The function `timespentsingle_calculator` returns a DataFrame containing the sum of time
    spent as a single woman for each woman ID based on the specified age group and time window. The
    exact time spent as single is calculated based on relationship formation and dissolution events
    within the provided data. The function allows for two types of calculations: "Strict" and "Harling",
    with different definitions for calculating the time spent single.
    """
    df = datalist["ptable"]
    events = datalist["etable"]

    # Define age and time window limits (Scalar values)
    lwr_age, upr_age = agegroup
    lwr_time, upr_time = timewindow

    # Filter persons table for women within the specified age and time bounds
    df = df[
        (df["Gender"] == 1)
        & ((df["TOB"] + lwr_age) <= upr_time)
        & ((df["TOB"] + upr_age) >= lwr_time)
    ].copy()

    # Determine the period of exposure for each woman
    df.loc[:, "time_lwr_agegroup"] = df["TOB"] + lwr_age
    df.loc[:, "time_upr_agegroup"] = df["TOB"] + upr_age
    df.loc[:, "exposure_start"] = np.maximum(df["time_lwr_agegroup"], lwr_time)
    df.loc[:, "exposure_end"] = np.minimum(
        df["time_upr_agegroup"], upr_time, df["InfectTime"]
    )
    df.loc[:, "exposure_time"] = (df["exposure_end"] - df["exposure_start"]).clip(
        lower=0
    )

    # If the exposure time is negative, then they had no exposure during the time window or age group of interest
    df.loc[:, "had_exposure_time"] = df["exposure_time"] > 0
    df.loc[:, "exposure_time"] = np.where(
        df["exposure_time"] < 0, 0, df["exposure_time"]
    )

    # Filter events related to relationship changes for women
    rel_events = events[
        (events["eventname"].isin(["formation", "dissolution"]))
        & (events["p2gender"] == 1)
        & (events["p2ID"].isin(df["ID"]))
    ]

    # Process relationship events to calculate single periods
    rel_events.sort_values(by=["p2ID", "eventtime"], inplace=True)
    rel_events["change"] = np.where(rel_events["eventname"] == "formation", 1, -1)
    rel_events["num_rels"] = rel_events.groupby("p2ID")["change"].cumsum()

    # Identify periods when women are single
    single_periods = rel_events[
        (rel_events["num_rels"].shift(1) == 0) & (rel_events["num_rels"] == 1)
    ]
    single_periods["single_start"] = single_periods["eventtime"]
    single_periods["single_end"] = single_periods.groupby("p2ID")["eventtime"].shift(-1)
    single_periods["single_time"] = (
        single_periods["single_end"] - single_periods["single_start"]
    ).clip(lower=0)

    if type == "Harling":
        # For the "Harling" definition, adjust to full-year blocks
        single_periods["year_start"] = single_periods["single_start"].apply(np.floor)
        single_periods["year_end"] = single_periods["single_end"].apply(np.ceil)
        single_periods["harling_time"] = (
            single_periods["year_end"] - single_periods["year_start"]
        ).clip(lower=0)
        result = single_periods.groupby("p2ID")["harling_time"].sum().reset_index()
    else:
        # For the "Strict" definition, use exact calculated times
        result = single_periods.groupby("p2ID")["single_time"].sum().reset_index()

    result.columns = ["woman_ID", "sum_norels_timespent"]
    return result

def incidence_calculator(datalist, agegroup, timewindow, only_active="No"):
    """
    Calculate HIV incidence, overall and stratified.

    Produces a data frame that contains the overall, and gender-stratified,
    HIV incidence at a specified time window and for a specific
    age group.

    Parameters:
    datalist (dict): The dictionary object that is produced by readthedata.
    agegroup (list): Boundaries of the age group (lower bound <= age < upper
                     bound) that should be retained. Should be expressed as a
                     list of two integers. e.g. [15, 30]
    timewindow (list): Boundaries of the time window (lower bound < time <= upper bound)
                       that should be retained. Should be expressed as a list of two integers.
                       e.g. [20, 30]
    only_active (str): Should only women who are in sexual relationships contribute
                       exposure time? Options are "Strict", "Harling", or "No".
                       Default is "No".

    Returns:
    pandas.DataFrame: A dataframe with cases, exposure times, incidence estimates,
                      and surrounding confidence bounds, for the specified time window
                      and age group, overall, and stratified by gender.

    Examples:
    cfg = {}
    modeloutput = RSimpactCyan.simpact.run(configParams=cfg, destDir="temp")
    dl = readthedata(modeloutput)
    incidence_df = incidence_calculator(datalist=dl, agegroup=[15, 30], timewindow=[20, 30])
    incidence_df
    """

    # Extract person table from datalist
    df = datalist['ptable']

    # Extract age group boundaries
    lwr_agegroup = agegroup[0]
    upr_agegroup = agegroup[1]

    # Extract time window boundaries
    lwr_timewindow = timewindow[0]
    upr_timewindow = timewindow[1]

    # Calculate naive exposure time
    df1 = df.assign(time_lwr_agegroup=df['TOB'] + lwr_agegroup,
                    time_upr_agegroup=df['TOB'] + upr_agegroup,
                    exposure_start=np.maximum(df['TOB'] + lwr_agegroup, lwr_timewindow),
                    exposure_end=np.minimum(np.minimum(df['InfectTime'].astype(float), df['TOB'] + upr_agegroup) , upr_timewindow))

    df2 = df1.assign(exposure_time=(df1['exposure_end'].astype(float) - df1['exposure_start'].astype(float)).clip(lower=0))

    # Filter individuals who had exposure time
    df3 = df2[df2['exposure_time'].astype(float) > 0]

    if df3.empty:
        # Return NaN dataframe if no observations
        incidence_df = pd.DataFrame({
            'Gender': [np.nan, np.nan, np.nan],
            'sum_exposure_time': [np.nan, np.nan, np.nan],
            'sum_incident_cases': [np.nan, np.nan, np.nan],
            'incidence': [np.nan, np.nan, np.nan],
            'incidence_95_ll': [np.nan, np.nan, np.nan],
            'incidence_95_ul': [np.nan, np.nan, np.nan]
        })
        return incidence_df

    # Calculate incidence by gender
    df4 = df3.assign(incident_case=(df3['InfectTime'].astype(float) > df3['exposure_start']) &
                                    (df3['InfectTime'].astype(float) <= df3['exposure_end']))

    if only_active != "No":
        # Additional calculations for "Strict" or "Harling"
        norels_timespent_df = timespentsingle_calculator(datalist=datalist, agegroup=agegroup,
                                                        timewindow=timewindow, type=only_active)

        df4 = pd.merge(df4, norels_timespent_df, left_on='ID', right_on='woman_ID', how='left')
        df4['sum_norels_timespent'] = df4['sum_norels_timespent'].fillna(0)
        df4['exposure_time'] -= df4['sum_norels_timespent']

    df5 = df4[df4['exposure_time'] >= 0]

    if df5.empty:
        # Return NaN dataframe if no observations after adjustments
        incidence_df = pd.DataFrame({
            'Gender': [np.nan, np.nan, np.nan],
            'sum_exposure_time': [np.nan, np.nan, np.nan],
            'sum_incident_cases': [np.nan, np.nan, np.nan],
            'incidence': [np.nan, np.nan, np.nan],
            'incidence_95_ll': [np.nan, np.nan, np.nan],
            'incidence_95_ul': [np.nan, np.nan, np.nan]
        })
        return incidence_df

    # Summarize incidence by gender
    incidence_df = df5.groupby('Gender').agg(
        sum_exposure_time=('exposure_time', 'sum'),
        sum_incident_cases=('incident_case', 'sum')
    ).reset_index()

    incidence_df['incidence'] = incidence_df['sum_incident_cases'] / incidence_df['sum_exposure_time']

    # Calculate exact confidence intervals for incidence
    def calc_ci(row):
        ci = poisson_exact(row['sum_incident_cases'], row['sum_exposure_time'])
        return pd.Series([ci[0], ci[1]])

    ci_values = incidence_df.apply(calc_ci, axis=1)
    incidence_df['incidence_95_ll'] = ci_values[0]
    incidence_df['incidence_95_ul'] = ci_values[1]

    # Calculate overall incidence
    overall_incidence = pd.DataFrame({
                    'Gender': ['Total'],
                    'sum_exposure_time': [df5['exposure_time'].sum()],
                    'sum_incident_cases': [df5['incident_case'].sum()]
                })

    overall_incidence['incidence'] = overall_incidence['sum_incident_cases'] / overall_incidence['sum_exposure_time']

    ci_overall = poisson_exact(overall_incidence['sum_incident_cases'].iloc[0],
                               overall_incidence['sum_exposure_time'].iloc[0])
    overall_incidence['incidence_95_ll'] = ci_overall[0]
    overall_incidence['incidence_95_ul'] = ci_overall[1]

    # Append overall incidence to incidence_df
    incidence_df = pd.concat([incidence_df, overall_incidence], ignore_index=True)

    # Return the final dataframe
    return incidence_df

def remove_files_in_folder(folder_path):
    # Check if the folder exists
    if not os.path.exists(folder_path):
        print(f"Folder '{folder_path}' does not exist.")
        return
    
    # List all files in the folder
    files = os.listdir(folder_path)
    
    # Iterate through the list and remove each file
    for file_name in files:
        file_path = os.path.join(folder_path, file_name)
        
        # Check if it is a file (and not a directory)
        if os.path.isfile(file_path):
            try:
                os.remove(file_path)
                # print(f"Removed file: {file_path}")
            except Exception as e:
                print(f"Error removing file {file_path}: {e}")
        else:
            try:
                shutil.rmtree(file_path)
                # print(f"Removed directory and its contents: {file_path}")
            except Exception as e:
                print(f"Error removing directory {file_path}: {e}")
